{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00869255",
   "metadata": {},
   "source": [
    "LangChainMemory\n",
    "```\n",
    "이전 대화 내용을 기억해서 문맥을 유지하는 역할 LangChain 0.3x 부터는 LCEL 기반으로 체인을 구성, RunnableWithMessageHistory, ChatMessageHistory 등의 컴포넌트를 활용해서 세션별 대화 기록을 관리, 대화가 장기화될 경우 요약 메모리를 도입해서 과거 대화를 LLM으로 요약하고 축약된 형태로 저장해서 프롬프트의 길이문제를 해결\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8d2b464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 환경설정\n",
    "%pip install --quiet langchain-openai langchain-community python-dotenv langchain_redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db98d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e95a6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: 안녕하세요 제 이름은 홍길동 입니다.\n",
      "ai: 안녕하세요 홍길동님, 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory # 인메모리 -> 어플리케이션 자체에 저장, 외부 불가능 #블로그 \n",
    "# 메모리 객체 생성\n",
    "history = InMemoryChatMessageHistory()\n",
    "history.add_user_message(\"안녕하세요 제 이름은 홍길동 입니다.\")\n",
    "history.add_ai_message(\"안녕하세요 홍길동님, 무엇을 도와드릴까요?\")\n",
    "# 현재까지의 대화 내용 확인\n",
    "for msg in history.messages:\n",
    "    print(f\"{msg.type}: {msg.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f81bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function os.getenv(key, default=None)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Radis 기반  채팅 기록 저장소\n",
    "# from langchain_redis import RedisChatMessageHistory\n",
    "# import os\n",
    "# REDIS_URL =os.getenv(\"REDIS_URL\",\"redis//localhost:6379\") # 환경변수에서 REDIS_URL을 가져오고, 없으면 기본값 사용\n",
    "# session_id = \"user_123\" # 세션 ID 설정\n",
    "# history = RedisChatMessageHistory(\n",
    "#     session_id=session_id,\n",
    "#     redis_url=REDIS_URL)\n",
    "# history.add_user_message(\"안녕하세요 제 이름은 홍길동 입니다.\")\n",
    "# history.add_ai_message(\"안녕하세요 홍길동님, 무엇을 도와드릴까요?\")\n",
    "# # 현재까지의 대화 내용 확인\n",
    "# for msg in history.messages:\n",
    "#     print(f\"{msg.type}: {msg.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "038349a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션기반 다중사용자 메모리 구조 구현 - 다중 사용자 챗봇\n",
    "# 핵심 : session_id를 키로하는 메모리 저장소 만들고 사용자의 대환느 키별로 저장한다.\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "# 프롬프트\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 뛰어난 한국어 상담 챗봇입니다 질문에 친절하고 자세히 답변해주세요.\"),\n",
    "     # history 키로 전달된 메세지 목록은 체인 실행 시 해당 위치에 넣겠다는 의미 \n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84f41b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae669faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션별 메모리 저장소를 딕셔너리로 만들고, 존재하지 않는 새로운 세세션 id가 들어오면 InMemoryChatMessageHistory를 생성\n",
    "# get_session_history를 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73053a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# 세션 id -> 대화 기록 전체 매핑 \n",
    "store = {}\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    \"\"\"세션 ID에 해당하는 대화 기록을 반환합니다. 존재하지 않으면 새로 생성합니다.\"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 메모리를 통합한 체인 래퍼 생성\n",
    "chatbot = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34fa3e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:37:39 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Session user_a 질문: 안녕하세요, 저는 홍길동입니다. 당신은 누구신가요?\n",
      "Session user_a 챗봇: 안녕하세요, 홍길동님! 저는 여러분의 질문에 답변하고 도움을 드리기 위해 만들어진 챗봇입니다. 어떤 궁금한 점이나 도움이 필요하신 부분이 있으신가요?\n",
      "\n",
      "16:37:40 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Session user_b 질문: 저는 김철수입니다. 당신은 어떤 일을 하시나요?\n",
      "Session user_b 챗봇: 안녕하세요, 김철수님! 저는 여러분의 질문에 답변하고, 정보 제공, 상담, 그리고 다양한 주제에 대해 대화하는 역할을 하는 챗봇입니다. 궁금한 점이나 도움이 필요한 부분이 있다면 언제든지 말씀해 주세요!\n",
      "\n",
      "16:37:43 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Session user_a 질문: 저는 프로그래머입니다. 당신은 어떤 일을 하시나요?\n",
      "Session user_a 챗봇: 저는 다양한 질문에 답변하고 정보를 제공하는 역할을 하고 있습니다. 프로그래밍, 기술, 과학, 문화 등 여러 분야에 대한 질문에 도움을 드릴 수 있습니다. 프로그래밍 관련해서 궁금한 점이나 도움이 필요하신 부분이 있다면 언제든지 말씀해 주세요!\n",
      "\n",
      "16:37:46 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Session user_b 질문: 저는 디자이너입니다. 요즘 어떤 프로젝트를 하고 계신가요?\n",
      "Session user_b 챗봇: 디자이너로서 다양한 프로젝트를 진행하고 계시군요! 저는 실제 프로젝트를 진행하지는 않지만, 디자인 관련 아이디어나 트렌드, 기술에 대한 정보를 제공할 수 있습니다. 현재 어떤 종류의 디자인 작업을 하고 계신가요? 그래픽 디자인, 웹 디자인, 제품 디자인 등 구체적으로 말씀해 주시면 더 도움이 될 수 있을 것 같습니다!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 두개의 세션을 번갈아가며 대화 RunnableWithMessageHistory 가 각 세션에 맞는 대화 기록을 관리합니다. \n",
    "sessions = ['user_a', 'user_b']\n",
    "questions = [\n",
    "    \"안녕하세요, 저는 홍길동입니다. 당신은 누구신가요?\", # user_a의 첫번째 질문\n",
    "    \"저는 김철수입니다. 당신은 어떤 일을 하시나요?\", # user_b의 첫번째 질문\n",
    "    \"저는 프로그래머입니다. 당신은 어떤 일을 하시나요?\",# user_a의 두번째 질문\n",
    "    \"저는 디자이너입니다. 요즘 어떤 프로젝트를 하고 계신가요?\" # user_b의 두번째 질문\n",
    "]\n",
    "for i, question in enumerate(questions):\n",
    "    session_id = sessions[i % 2]  # 세션 ID를 번갈아가며 사용\n",
    "    result = chatbot.invoke({'input': question},config={'configurable': {'session_id': session_id}})\n",
    "    print(f\"Session {session_id} 질문: {question}\")\n",
    "    print(f\"Session {session_id} 챗봇: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33e34a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:40:20 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Session user_c 질문: 저는 철수에요, 반갑습니다\n",
      "Session user_c 챗봇: 안녕하세요, 철수님! 반갑습니다. 어떻게 도와드릴까요? 궁금한 점이나 이야기하고 싶은 것이 있다면 말씀해 주세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"저는 철수에요, 반갑습니다\"},config={'configurable': {'session_id': 'user_c'}})\n",
    "print(f\"Session user_c 질문: 저는 철수에요, 반갑습니다\")\n",
    "print(f\"Session user_c 챗봇: {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e917f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:42:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'홍길동님이라고 말씀하셨습니다! 혹시 더 알고 싶으신 내용이나 다른 질문이 있으신가요?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"저는 누구라고요?\"},config={'configurable': {'session_id': 'user_a'}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fd20a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:43:16 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'김철수님이라고 말씀하셨습니다! 혹시 더 궁금한 점이나 다른 질문이 있으신가요? 언제든지 말씀해 주세요!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"저는 누구라고요?\"},config={'configurable': {'session_id': 'user_b'}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d63e0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:43:26 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'철수님이라고 말씀하셨습니다! 혹시 더 궁금한 점이나 다른 이야기를 나누고 싶으신가요?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"저는 누구라고요?\"},config={'configurable': {'session_id': 'user_c'}})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc84373",
   "metadata": {},
   "source": [
    "요약 메모리 구현(대화내용 자동 요약)\n",
    "```\n",
    "긴 대화내용을 모두 프롬프트에 기록하는 것은 비효율적 -> 프롬프트의 길이 제한에 걸릴 가능성이 있음\n",
    "Conversation Summary Memory\n",
    "0.3x 버젼에서는 직접 요약용 체인을 만들어서 chatMessageHistory\n",
    "```\n",
    "어떻게 요약?\n",
    "```\n",
    "- 일정길이 이상으로 대화가 누적되면, 과거 대화를 요약해서 핵심내용만 남김\n",
    "- 요약결과를 메모리에 시스템 메세지 등으로 저장 -> 메모리 절약\n",
    "- 새로운 사용자 입력시 요약된 맥락 + 최근 몇 메시지만 참고해서 llm 전달\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03699a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약용 프롬프트 탬플릿\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 대화 요약 전문가입니다. 대화의 주요 내용을 간결하게 요약해 주세요.\"),\n",
    "    (\"human\", \"{conversation}\"), # 전체 대화내용을 하나의 문자열로 전달\n",
    "])\n",
    "# LCEL\n",
    "summary_chain = summary_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0512d5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['user_a', 'user_b', 'user_c'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.keys() # 현재 저장된 세션 ID 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5725e09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:25:14 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:25:16 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:25:19 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:25:22 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17:25:24 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "요약전 user_d의 메모리 메시지 개수 : 10\n",
      "Human: 안녕, 우리 오늘 뭐하려고 했지?\n",
      "AI: 안녕하세요! 오늘 어떤 주제에 대해 이야기하고 싶으신가요? 궁금한 점이나 나누고 싶은 이야기가 있다면 말씀해 주세요. 함께 이야기해보아요!\n",
      "Human: 아 맞다 내일 회의자료 준비해야지, 회의는 몇시지지?\n",
      "AI: 회의 시간이 기억나지 않으신가요? 회의 일정은 보통 이메일이나 캘린더에 기록되어 있을 텐데요. 확인해보시고, 만약 찾기 어렵다면 회의 주최자에게 직접 문의해보시는 것도 좋은 방법입니다. 회의 준비에 도움이 필요하시면 말씀해 주세요! 어떤 자료를 준비해야 하는지에 대해서도 도와드릴 수 있습니다.\n",
      "Human: 그 회의에 누가 참석하는지 기억나니니?\n",
      "AI: 회의 참석자에 대한 정보는 제가 알 수 없지만, 보통 회의 초대 이메일이나 캘린더 초대장에 참석자 목록이 포함되어 있습니다. 그곳에서 확인해보시면 좋을 것 같아요. 만약 참석자 목록을 정리해야 하거나, 회의에 대해 더 준비할 것이 필요하다면 말씀해 주세요! 도움이 될 수 있는 부분이 있다면 기꺼이 도와드리겠습니다.\n",
      "Human: 단위프로젝트 진행 상황도 공유해야 할끼?\n",
      "AI: 네, 단위 프로젝트의 진행 상황을 공유하는 것은 회의에서 중요한 부분일 수 있습니다. 참석자들이 프로젝트의 현재 상태를 이해하고, 필요한 피드백이나 지원을 받을 수 있도록 하는 것이 좋습니다. \n",
      "\n",
      "진행 상황을 공유할 때는 다음과 같은 내용을 포함하면 좋습니다:\n",
      "\n",
      "1. **프로젝트 목표**: 프로젝트의 목표와 방향성을 간단히 설명합니다.\n",
      "2. **진행 상황**: 현재까지 완료된 작업과 진행 중인 작업을 정리합니다.\n",
      "3. **문제점 및 해결 방안**: 진행 중에 발생한 문제와 그에 대한 해결 방안을 공유합니다.\n",
      "4. **다음 단계**: 앞으로의 계획과 일정에 대해 설명합니다.\n",
      "\n",
      "이런 정보를 준비하면 회의에서 더 효과적으로 소통할 수 있을 것입니다. 추가로 도움이 필요하시면 언제든지 말씀해 주세요!\n",
      "Human: 최근에 이야기 했던 새로운 기능에대한 업데이트는 있어?\n",
      "AI: 새로운 기능에 대한 업데이트는 보통 프로젝트 팀이나 개발팀에서 정기적으로 공유하는 정보입니다. 만약 그 기능에 대한 구체적인 내용이나 업데이트가 필요하시다면, 관련 팀이나 담당자에게 직접 문의해보시는 것이 좋습니다. \n",
      "\n",
      "또한, 회의에서 해당 기능에 대한 진행 상황이나 업데이트를 공유할 수 있도록 준비해두면 좋을 것 같습니다. 필요한 경우, 업데이트 내용을 정리하는 데 도움을 드릴 수 있으니 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# user_d 세션에 대화내용을 기록 긴 대화 생성\n",
    "long_quries = [\n",
    "    \"안녕, 우리 오늘 뭐하려고 했지?\",\n",
    "    \"아 맞다 내일 회의자료 준비해야지, 회의는 몇시지지?\",\n",
    "    \"그 회의에 누가 참석하는지 기억나니니?\",\n",
    "    \"단위프로젝트 진행 상황도 공유해야 할끼?\",\n",
    "    \"최근에 이야기 했던 새로운 기능에대한 업데이트는 있어?\",\n",
    "]\n",
    "session_id = 'user_d'\n",
    "for q in long_quries:\n",
    "    answer = chatbot.invoke({'input': q},config={'configurable': {'session_id': session_id}})\n",
    "\n",
    "print(f'요약전 user_d의 메모리 메시지 개수 : {len(store[session_id].messages)}')\n",
    "print(store[session_id]) # 요약하기전 대화 내용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe1ad6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:48:37 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "== 요약 결과 ==\n",
      "대화 요약:\n",
      "\n",
      "HUMAN은 내일 회의 자료를 준비해야 한다고 언급하며 회의 시간을 확인하려고 했다. AI는 회의 일정이 이메일이나 캘린더에 기록되어 있을 것이라고 안내하고, 참석자 목록도 그곳에서 확인할 수 있다고 설명했다. HUMAN은 단위 프로젝트의 진행 상황을 공유해야 하는지 물었고, AI는 진행 상황 공유의 중요성을 강조하며 포함해야 할 내용(프로젝트 목표, 진행 상황, 문제점 및 해결 방안, 다음 단계)을 제안했다.\n"
     ]
    }
   ],
   "source": [
    "# 전체대화 내용을 요약하고 마지막 사용자 질문-답변 쌍만 원보 유지\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "# 요약 대상 대화내용 추출(마지막 QA 쌍 제외한 이전 내용)\n",
    "message = store[session_id].messages\n",
    "\n",
    "if len(message) > 2:\n",
    "    original_dialog = '\\n'.join([f'{msg.type.upper()},{msg.content}' for msg in message[:-2]])  # 마지막 QA 쌍 제외\n",
    "else:\n",
    "    original_dialog = '\\n'.join([f'{msg.type.upper()},{msg.content}' for msg in message])\n",
    "\n",
    "# llm으로 요약 생성\n",
    "summary_text = summary_chain.invoke({'conversation': original_dialog})\n",
    "print(\"== 요약 결과 ==\")\n",
    "print(summary_text)\n",
    "# 기존 메모리를 요약으로 교체 : 이전내용 요약본 + 최근 QA유지\n",
    "new_history = InMemoryChatMessageHistory()\n",
    "new_history.messages.append(SystemMessage(content=f\"요약:{summary_text}\"))\n",
    "# 최근 대화의 마지막 QA쌍 복원\n",
    "if len(message) >= 2:\n",
    "    last_user_message = message[-2]\n",
    "    last_ai_message = message[-1]\n",
    "    if isinstance(last_user_message, HumanMessage):\n",
    "        new_history.add_user_message(last_user_message.content)\n",
    "    else:\n",
    "        new_history.messages.append(last_user_message)\n",
    "    if isinstance(last_ai_message, AIMessage):\n",
    "        new_history.add_ai_message(last_ai_message.content)\n",
    "    else:\n",
    "        new_history.messages.append(last_ai_message)\n",
    "\n",
    "# 메모리 교체\n",
    "store[session_id] = new_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90764533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(store[session_id].messages))  # 요약 후 대화 내용 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
