{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00869255",
   "metadata": {},
   "source": [
    "LangChainMemory\n",
    "```\n",
    "이전 대화 내용을 기억해서 문맥을 유지하는 역할 LangChain 0.3x 부터는 LCEL 기반으로 체인을 구성, RunnableWithMessageHistory, ChatMessageHistory 등의 컴포넌트를 활용해서 세션별 대화 기록을 관리, 대화가 장기화될 경우 요약 메모리를 도입해서 과거 대화를 LLM으로 요약하고 축약된 형태로 저장해서 프롬프트의 길이문제를 해결\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8d2b464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 환경설정\n",
    "%pip install --quiet langchain-openai langchain-community python-dotenv langchain_redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db98d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e95a6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: 안녕하세요 제 이름은 홍길동 입니다.\n",
      "ai: 안녕하세요 홍길동님, 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory # 인메모리 -> 어플리케이션 자체에 저장, 외부 불가능 #블로그 \n",
    "# 메모리 객체 생성\n",
    "history = InMemoryChatMessageHistory()\n",
    "history.add_user_message(\"안녕하세요 제 이름은 홍길동 입니다.\")\n",
    "history.add_ai_message(\"안녕하세요 홍길동님, 무엇을 도와드릴까요?\")\n",
    "# 현재까지의 대화 내용 확인\n",
    "for msg in history.messages:\n",
    "    print(f\"{msg.type}: {msg.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f81bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function os.getenv(key, default=None)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Radis 기반  채팅 기록 저장소\n",
    "# from langchain_redis import RedisChatMessageHistory\n",
    "# import os\n",
    "# REDIS_URL =os.getenv(\"REDIS_URL\",\"redis//localhost:6379\") # 환경변수에서 REDIS_URL을 가져오고, 없으면 기본값 사용\n",
    "# session_id = \"user_123\" # 세션 ID 설정\n",
    "# history = RedisChatMessageHistory(\n",
    "#     session_id=session_id,\n",
    "#     redis_url=REDIS_URL)\n",
    "# history.add_user_message(\"안녕하세요 제 이름은 홍길동 입니다.\")\n",
    "# history.add_ai_message(\"안녕하세요 홍길동님, 무엇을 도와드릴까요?\")\n",
    "# # 현재까지의 대화 내용 확인\n",
    "# for msg in history.messages:\n",
    "#     print(f\"{msg.type}: {msg.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "038349a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션기반 다중사용자 메모리 구조 구현 - 다중 사용자 챗봇\n",
    "# 핵심 : session_id를 키로하는 메모리 저장소 만들고 사용자의 대환느 키별로 저장한다.\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "# 프롬프트\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 뛰어난 한국어 상담 챗봇입니다 질문에 친절하고 자세히 답변해주세요.\"),\n",
    "     # history 키로 전달된 메세지 목록은 체인 실행 시 해당 위치에 넣겠다는 의미 \n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84f41b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae669faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션별 메모리 저장소를 딕셔너리로 만들고, 존재하지 않는 새로운 세세션 id가 들어오면 InMemoryChatMessageHistory를 생성\n",
    "# get_session_history를 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73053a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# 세션 id -> 대화 기록 전체 매핑 \n",
    "store = {}\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    \"\"\"세션 ID에 해당하는 대화 기록을 반환합니다. 존재하지 않으면 새로 생성합니다.\"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 메모리를 통합한 체인 래퍼 생성\n",
    "chatbot = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34fa3e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:37:39 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Session user_a 질문: 안녕하세요, 저는 홍길동입니다. 당신은 누구신가요?\n",
      "Session user_a 챗봇: 안녕하세요, 홍길동님! 저는 여러분의 질문에 답변하고 도움을 드리기 위해 만들어진 챗봇입니다. 어떤 궁금한 점이나 도움이 필요하신 부분이 있으신가요?\n",
      "\n",
      "16:37:40 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Session user_b 질문: 저는 김철수입니다. 당신은 어떤 일을 하시나요?\n",
      "Session user_b 챗봇: 안녕하세요, 김철수님! 저는 여러분의 질문에 답변하고, 정보 제공, 상담, 그리고 다양한 주제에 대해 대화하는 역할을 하는 챗봇입니다. 궁금한 점이나 도움이 필요한 부분이 있다면 언제든지 말씀해 주세요!\n",
      "\n",
      "16:37:43 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Session user_a 질문: 저는 프로그래머입니다. 당신은 어떤 일을 하시나요?\n",
      "Session user_a 챗봇: 저는 다양한 질문에 답변하고 정보를 제공하는 역할을 하고 있습니다. 프로그래밍, 기술, 과학, 문화 등 여러 분야에 대한 질문에 도움을 드릴 수 있습니다. 프로그래밍 관련해서 궁금한 점이나 도움이 필요하신 부분이 있다면 언제든지 말씀해 주세요!\n",
      "\n",
      "16:37:46 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Session user_b 질문: 저는 디자이너입니다. 요즘 어떤 프로젝트를 하고 계신가요?\n",
      "Session user_b 챗봇: 디자이너로서 다양한 프로젝트를 진행하고 계시군요! 저는 실제 프로젝트를 진행하지는 않지만, 디자인 관련 아이디어나 트렌드, 기술에 대한 정보를 제공할 수 있습니다. 현재 어떤 종류의 디자인 작업을 하고 계신가요? 그래픽 디자인, 웹 디자인, 제품 디자인 등 구체적으로 말씀해 주시면 더 도움이 될 수 있을 것 같습니다!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 두개의 세션을 번갈아가며 대화 RunnableWithMessageHistory 가 각 세션에 맞는 대화 기록을 관리합니다. \n",
    "sessions = ['user_a', 'user_b']\n",
    "questions = [\n",
    "    \"안녕하세요, 저는 홍길동입니다. 당신은 누구신가요?\", # user_a의 첫번째 질문\n",
    "    \"저는 김철수입니다. 당신은 어떤 일을 하시나요?\", # user_b의 첫번째 질문\n",
    "    \"저는 프로그래머입니다. 당신은 어떤 일을 하시나요?\",# user_a의 두번째 질문\n",
    "    \"저는 디자이너입니다. 요즘 어떤 프로젝트를 하고 계신가요?\" # user_b의 두번째 질문\n",
    "]\n",
    "for i, question in enumerate(questions):\n",
    "    session_id = sessions[i % 2]  # 세션 ID를 번갈아가며 사용\n",
    "    result = chatbot.invoke({'input': question},config={'configurable': {'session_id': session_id}})\n",
    "    print(f\"Session {session_id} 질문: {question}\")\n",
    "    print(f\"Session {session_id} 챗봇: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33e34a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:40:20 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Session user_c 질문: 저는 철수에요, 반갑습니다\n",
      "Session user_c 챗봇: 안녕하세요, 철수님! 반갑습니다. 어떻게 도와드릴까요? 궁금한 점이나 이야기하고 싶은 것이 있다면 말씀해 주세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"저는 철수에요, 반갑습니다\"},config={'configurable': {'session_id': 'user_c'}})\n",
    "print(f\"Session user_c 질문: 저는 철수에요, 반갑습니다\")\n",
    "print(f\"Session user_c 챗봇: {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e917f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:42:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'홍길동님이라고 말씀하셨습니다! 혹시 더 알고 싶으신 내용이나 다른 질문이 있으신가요?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"저는 누구라고요?\"},config={'configurable': {'session_id': 'user_a'}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fd20a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:43:16 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'김철수님이라고 말씀하셨습니다! 혹시 더 궁금한 점이나 다른 질문이 있으신가요? 언제든지 말씀해 주세요!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"저는 누구라고요?\"},config={'configurable': {'session_id': 'user_b'}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d63e0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:43:26 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'철수님이라고 말씀하셨습니다! 혹시 더 궁금한 점이나 다른 이야기를 나누고 싶으신가요?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chatbot.invoke({'input': \"저는 누구라고요?\"},config={'configurable': {'session_id': 'user_c'}})\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
